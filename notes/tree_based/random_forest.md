
## bootstrapping
bootstrapped training samples

## column sampling
To build decorrelated desicion trees, choose m predictors from the full set of p predictors. Usually, m = squared p. So, even there is a strong predictor, we can still build trees based on different predictors.


## feature importance
computed using the mean decrease in Gini index

## OOB
out of bag: use the unchosen data (after bootstrapping) as the validation dataset