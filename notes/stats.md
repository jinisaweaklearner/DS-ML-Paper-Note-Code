### Bias and Variance
underfitting: high bias and low variance
overfitting: high variance and low bias 

### Kurtosis
Kurtosis is all about the tails of the distribution â€” not the peakedness or flatness. It is used to describe the extreme values in one versus the other tail. It is actually the measure of outliers present in the distribution.
![](https://cdn.mathpix.com/snip/images/2vz-frI-p-uLF5Nh006sWvXctpPY-gsAyJQvQnMQXBw.original.fullsize.png)

### Skewness
- If the skewness is between -0.5 and 0.5, the data are fairly symmetrical.
- If the skewness is between -1 and -0.5(negatively skewed) or between 0.5 and 1(positively skewed), the data are moderately skewed.
- If the skewness is less than -1(negatively skewed) or greater than 1(positively skewed), the data are highly skewed.

![](https://cdn.mathpix.com/snip/images/7hkRIZgmY1mN4VlvaoSSjifmWHfby1-5zYQlpaQM9fw.original.fullsize.png)


### standard deviation 
Standard deviation quantifies the variation of data points.
![](https://cdn.mathpix.com/snip/images/2LK8RAGEH7CqFPhujh-izggTlrD1jG80SvHooshpz1g.original.fullsize.png)
![](https://cdn.mathpix.com/snip/images/6ZpUYn4g1e1qC_HgEx_7LXgyggok8IoILkD3UC-Kxkg.original.fullsize.png)

### Residual standard error 
why n-2 in Residual standard error and n-1 in variance?
The degree of freedom

https://stats.stackexchange.com/questions/201352/why-divide-by-n-2-for-residual-standard-errors

### R square
The sum of squares due to regression measures how well the regression model represents the data that were used for modeling. To calculate R2 you need to find `the sum of the residuals squared` and `the total sum of squares`.
![](https://cdn.mathpix.com/snip/images/0d4xq7hLpkuC8GCUsgV35_DojnFa4f1_PNSlxP5-B-o.original.fullsize.png)

why use R2?
- there are upper bound and lower bound

### Adjusted R square
consider number of observation and number of features


### Correlation 
![](http://www.resacorp.com/images/slrund031.gif)

