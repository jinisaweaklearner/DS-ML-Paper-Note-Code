# Papers, Notes and Code in Data Science and Machine learning

## Tree-based

|Model Name | Category | Paper  | Notes   | Code  |
|---|:---:|:---:|:---:|:---:|
| Decision Tree (ID3,C4.5,CART) | -  | -  | [Notes](notes/decision_tree.md)   |   |
| Random Forest  |  bagging |   |  [Notes](notes/random_forest.md)  |    |
| AdaBoost: Adaptive Boosting  |  boosting |   | [Notes](notes/adaboost.md) | [Code](AdaboostClassification.ipynb)  |
| GBDT: Gradient Boosting Decision Tree  |  boosting |   | [Notes](notes/gbdt.md)   | [Code](https://github.com/jinisaweaklearner/DS-ML-Paper-Note-Code/blob/master/src/GradientBoostingDecisionTree(GBDT).ipynb)  |
| LightGBM: A Highly Efficient Gradient Boosting Decision Tree |  boosting |[Paper](https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf) |  [Notes](notes/lightgbm.md)  |   |
| XGBoost: A Scalable Tree Boosting System  |  boosting | [Paper](https://arxiv.org/pdf/1603.02754.pdf)  | [Notes](notes/xgboost.md)   |   |
| CatBoost: unbiased boosting with categorical features  |  boosting | [Paper](https://arxiv.org/pdf/1706.09516.pdf) | [Notes](notes/catboost.md)   |   |
| Deep Forest: Towards an Alternative to Deep Neural Networks  |  - | [Paper](https://arxiv.org/pdf/1702.08835v2.pdf) |  |[Github](https://github.com/kingfengji/gcForest)  |


## Auto ML
- H2O AutoML [[Code]](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html) 

## SVM
- SVM [[Notes]](notes/svm.md)

## Dimention Reduction
- PCA PCR PLS [[Notes]](notes/dimention_reduction.md)
- MDS
- t-SNE
- Auto Encoder

## Non Linear Methods
- Polynomial Regression [[Notes]](notes/nonlinear_methods.md)
- Step functions [[Notes]](notes/nonlinear_methods.md)
- Regression splines [[Notes]](notes/nonlinear_methods.md)
- Local Regression [[Notes]](notes/nonlinear_methods.md)
- Generalized additive models [[Notes]](notes/nonlinear_methods.md)

## NLP Pre-trained Model
- RoBERTa: A Robustly Optimized BERT Pretraining Approach [[Paper]](https://arxiv.org/pdf/1907.11692.pdf) [[Code]](src/RoBERTa_multi_class_yelp5.ipynb) 
- ULMFiT: Universal Language Model Fine-tuning for Text Classification [[Paper]](https://arxiv.org/pdf/1801.06146.pdf)
- GPT2: Language Models are Unsupervised Multitask Learners [[Paper]](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) [[Code]](https://github.com/openai/gpt-2)
- BERT: Pre-training of Deep Bidirectional Transformers for
Language Understanding [[Paper]](https://arxiv.org/pdf/1810.04805.pdf)

## Sequential
- LSTM 
- BiLSTM
- GRU
- RNN
- HMM

## Traditional Time Series Forecasting
- Time Series Ebook [[Link]](https://otexts.com/fpp2/ets-forecasting.html)
- Naïve 
- Seasonal Naïve
- Simple Exponential Smoothing
- ARIMA
- Moving Averages 
- Prophet

## Rating System
- Elo [[wiki]](https://en.wikipedia.org/wiki/Elo_rating_system)
- Glicko [[Paper]](http://www.glicko.net/research/acjpaper.pdf)
- Glicko2 [[Code]](https://bitbucket.org/deepy/glicko2/src/default/)
- Trueskill: A Bayesian Skill Rating System  [[Web]](https://trueskill.org/) [[Paper]](https://www.microsoft.com/en-us/research/wp-content/uploads/2007/01/NIPS2006_0688.pdf)


## Anomaly Detection
- Isolation Forest [[Paper]](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf?q=isolation-forest) [[Video]](https://www.youtube.com/watch?v=5p8B2Ikcw-k) 
- One-Class SVM
- Local Outlier Factor
- Robust Covariance


## Imbalanced Problem
* SMOTE: Synthetic Minority Over-sampling Technique [[Paper]](https://arxiv.org/pdf/1106.1813.pdf) [[Notes]](notes/Smote.md)

## Model Interpretation
* SHAP: A Unified Approach to Interpreting Model
Predictions [[Paper]](https://arxiv.org/pdf/1705.07874.pdf)
* LIME: “Why Should I Trust You?”
Explaining the Predictions of Any Classifier [[Paper]](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf?q=isolation-forest)

## Feature Selection, Engineering and Deduction
- mRMR: Maximum Relevance and Minimum Redundancy [[Paper]](http://home.penglab.com/papersall/docpdf/2005_TPAMI_FeaSel.pdf) [[Github]](https://github.com/fbrundu/pymrmr)
- Autoencoder

## Model Validation
- We need to talk about standard splits [[Paper]](https://pdfs.semanticscholar.org/94be/fec2a6d96e3a60fb8b77f2e161666743c1a5.pdf)
- Adversarial Validation: solve the problem  [[Part1]](http://fastml.com/adversarial-validation-part-one/) [[Part2]](http://fastml.com/adversarial-validation-part-two/) [[Video]](https://www.youtube.com/watch?v=7cUCDRaIZ7I) [[Code]](https://github.com/zjost/blog_code/blob/master/adversarial_validation/adversarial-validation-example.ipynb)

## AB Testing 
-  P Value, effect size and power analysis [[Notes]](notes/p_value.md)


