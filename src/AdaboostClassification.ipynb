{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdaboostClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPpmRzEAN+baAix3zQz1F5b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinisaweaklearner/DS-ML-Paper-Note-Code/blob/master/src/AdaboostClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVpu8BJbFFau"
      },
      "source": [
        "\n",
        "\n",
        "# Import Packages\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-p_8bF7E_2V"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.tree import export_graphviz\n",
        "from pydotplus import graph_from_dot_data\n",
        "from IPython.display import Image\n",
        "from sklearn.tree import export_text\n",
        "from sklearn.tree import _tree\n",
        "\n",
        "from sklearn.datasets import make_gaussian_quantiles\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# https://geoffruddock.com/adaboost-from-scratch-in-python/"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9Jj8U22FOtM"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktucug3FFNvY"
      },
      "source": [
        "def make_toy_dataset(n: int = 100, random_seed: int = None):\n",
        "    \"\"\" Generate a toy dataset for evaluating AdaBoost classifiers \"\"\"\n",
        "    \n",
        "    n_per_class = int(n/2)\n",
        "    \n",
        "    if random_seed:\n",
        "        np.random.seed(random_seed)\n",
        "\n",
        "    X, y = make_gaussian_quantiles(n_samples=n, n_features=2, n_classes=2)\n",
        "    \n",
        "    return X, y*2-1\n",
        "\n",
        "X, y = make_toy_dataset(n=10, random_seed=10) "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqBBcgVJForW"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uNJPhbtY7Pl"
      },
      "source": [
        "n_trees = 3"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LXir2dwbSvt"
      },
      "source": [
        "class AdaBoostClassification:\n",
        "    \"\"\" AdaBoost enemble classifier from scratch \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.stumps = None\n",
        "        self.stump_weights = None\n",
        "        self.errors = None\n",
        "        self.sample_weights = None\n",
        "\n",
        "    def _check_X_y(self, X, y):\n",
        "        \"\"\" Validate assumptions about format of input data\"\"\"\n",
        "        assert set(y) == {-1, 1}, 'Response variable must be Â±1'\n",
        "        return X, y\n",
        "\n",
        "def fit(self, X: np.ndarray, y: np.ndarray, iters: int):\n",
        "    \"\"\" Fit the model using training data \"\"\"\n",
        "\n",
        "    X, y = self._check_X_y(X, y)\n",
        "    n = X.shape[0]\n",
        "\n",
        "    # init numpy arrays\n",
        "    self.sample_weights = np.zeros(shape=(iters, n))\n",
        "    self.stumps = np.zeros(shape=iters, dtype=object)\n",
        "    self.stump_weights = np.zeros(shape=iters)\n",
        "    self.errors = np.zeros(shape=iters)\n",
        "\n",
        "    # initialize weights uniformly\n",
        "    self.sample_weights[0] = np.ones(shape=n) / n\n",
        "\n",
        "    print('ground Truth:', y)\n",
        "\n",
        "    for t in range(iters):\n",
        "\n",
        "        print(t)\n",
        "\n",
        "        # fit  weak learner\n",
        "        curr_sample_weights = self.sample_weights[t]\n",
        "        print('weights: ',curr_sample_weights)\n",
        "        stump = DecisionTreeClassifier(max_depth=1, max_leaf_nodes=2,random_state=42)\n",
        "        stump = stump.fit(X, y, sample_weight=curr_sample_weights)\n",
        "\n",
        "        # calculate error and stump weight from weak learner prediction\n",
        "        stump_pred = stump.predict(X)\n",
        "        print('prediction: ',stump_pred)\n",
        "        err = curr_sample_weights[(stump_pred != y)].sum() \n",
        "        print('error: ',round(err,2))\n",
        "        stump_weight = np.log((1 - err) / err) / 2\n",
        "\n",
        "        # update sample weights\n",
        "        new_sample_weights = (\n",
        "            curr_sample_weights * np.exp(-stump_weight * y * stump_pred)\n",
        "        )\n",
        "        \n",
        "        # normalize weights\n",
        "        new_sample_weights /= new_sample_weights.sum()\n",
        "\n",
        "        # If not final iteration, update sample weights for t+1\n",
        "        if t+1 < iters:\n",
        "            self.sample_weights[t+1] = new_sample_weights\n",
        "\n",
        "        print('total weights:', stump_weight)\n",
        "        # print(new_sample_weights,'\\n')\n",
        "        # save results of iteration\n",
        "        self.stumps[t] = stump\n",
        "        self.stump_weights[t] = stump_weight\n",
        "        self.errors[t] = err\n",
        "\n",
        "    return self\n",
        "\n",
        "def predict(self, X):\n",
        "    \"\"\" Make predictions using already fitted model \"\"\"\n",
        "    # get all predictions of each iteration\n",
        "    stump_preds = np.array([stump.predict(X) for stump in self.stumps])\n",
        "\n",
        "    # predictions(10*3) * weights (3)\n",
        "    pred_prob = np.dot(self.stump_weights, stump_preds)\n",
        "    return pred_prob, np.sign(pred_prob)  \n",
        "\n",
        "AdaBoostClassification.fit = fit\n",
        "AdaBoostClassification.predict = predict      "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeUsyKC8EsvX",
        "outputId": "fb964dc7-0654-4c35-ae00-9491054ab6e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf = AdaBoostClassification().fit(X, y, iters=n_trees)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ground Truth: [-1  1  1 -1 -1 -1  1  1 -1  1]\n",
            "0\n",
            "weights:  [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "prediction:  [-1  1  1 -1 -1 -1 -1  1 -1 -1]\n",
            "error:  0.2\n",
            "total weights: 0.6931471805599453\n",
            "1\n",
            "weights:  [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.25   0.0625 0.0625 0.25  ]\n",
            "prediction:  [1 1 1 1 1 1 1 1 1 1]\n",
            "error:  0.31\n",
            "total weights: 0.39422868018213514\n",
            "2\n",
            "weights:  [0.1        0.04545455 0.04545455 0.1        0.1        0.1\n",
            " 0.18181818 0.04545455 0.1        0.18181818]\n",
            "prediction:  [-1 -1 -1 -1 -1 -1 -1  1 -1  1]\n",
            "error:  0.27\n",
            "total weights: 0.49041462650586315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t-CXRbScjj_",
        "outputId": "cb02cc2b-a9a6-4090-a3d2-3e2b087e9ba0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pred_prob,final_pred = clf.predict(X)\n",
        "train_err = (final_pred != y).mean()\n",
        "print('final_pred',final_pred)\n",
        "print('pred_prob',pred_prob)\n",
        "print(f'Train error: {train_err:.1%}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final_pred [-1.  1.  1. -1. -1. -1. -1.  1. -1.  1.]\n",
            "pred_prob [-0.78933313  0.59696123  0.59696123 -0.78933313 -0.78933313 -0.78933313\n",
            " -0.78933313  1.57779049 -0.78933313  0.19149613]\n",
            "Train error: 10.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1NHsmlrZ7t3"
      },
      "source": [
        "## cross check the result by using packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tT1n5XieJRE",
        "outputId": "40c089da-2e3b-48dd-d3ec-95105a28b332",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf_package = AdaBoostClassifier(n_estimators=n_trees, random_state=42)\n",
        "clf_package.fit(X, y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
              "                   n_estimators=3, random_state=42)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyw5_isfeJW4",
        "outputId": "907c4f43-3b20-40b1-a753-01a7d4cbce66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf_package.estimator_weights_"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ0Hvvd1iqNj",
        "outputId": "50b7a941-0f60-4ff8-e12d-e6968cf10ee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in clf_package.staged_predict(X):\n",
        "    print(i)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1  1  1 -1 -1 -1 -1  1 -1 -1]\n",
            "[-1  1  1 -1 -1 -1 -1  1 -1 -1]\n",
            "[-1  1  1 -1 -1 -1 -1  1 -1  1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4L_SCUzeb3V"
      },
      "source": [
        "# for i in clf_package.staged_predict_proba(X):\n",
        "#     print(i)"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}